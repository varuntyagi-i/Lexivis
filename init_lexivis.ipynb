{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Loading Credentials\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "api_version = os.getenv(\"API_VERSION\")\n",
    "api_endpoint = os.getenv(\"AZURE_BASE_URL\")\n",
    "together_api = os.getenv(\"TOGETHER_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install gdown\n",
    "\n",
    "# !gdown 1yVbhJWh4L1unDbDT4APOusTXlwic7aE9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Text and IMages from the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* here we can check how to pass the base64 encoded images to open ai model for usage\n",
    "* note that the variable name for the image is still image_url, but we pass the image in base64 format\n",
    "\n",
    "https://platform.openai.com/docs/guides/vision/uploading-base-64-encoded-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "# Open the image file and encode it as a base64 string\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=api_endpoint)\n",
    "\n",
    "\n",
    "def describe_image(base64_image):\n",
    "    \"\"\"\n",
    "    Uses OpenAI's GPT-4o model to generate a description of the image.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt-4o-mini\",\n",
    "      messages=[\n",
    "        { \"role\": \"system\", \"content\": \"Your job is to extract all the information from the images, includng the text. Extract all the text from the image without changing the order or structure of the information. recheck if all the text has been extracted correctly and return in the same presentation and structure as present in the original image. \"},\n",
    "         { \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"extract ALL the text from the image in the same structure as present in the image. and then after it summarise everything in brief, do not miss anything \"},\n",
    "            {\n",
    "              \"type\": \"image_url\",\n",
    "              \"image_url\": {\n",
    "                \"url\": f\"data:image/png;base64,{base64_image}\",\n",
    "              },\n",
    "            },\n",
    "          ],\n",
    "        }\n",
    "      ],\n",
    "      max_tokens=300,\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import fitz  # PyMuPDF wrapper for simplicity\n",
    "\n",
    "def extract_images_and_text_from_pdf(pdf_path, output_folder):\n",
    "    # Open the PDF file\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Initialize a variable to store the combined text\n",
    "    combined_text = \"\"\n",
    "\n",
    "    # Loop through each page\n",
    "    for page_number in range(len(pdf_document)):\n",
    "        \n",
    "        # Only testing till page number 10, main purpose is to build and end-to-end pipeline\n",
    "        if page_number > 10:\n",
    "            break\n",
    "\n",
    "        page = pdf_document.load_page(page_number)\n",
    "\n",
    "        # Loading text from pdf\n",
    "        text = page.get_text()\n",
    "\n",
    "        # Add the text of the current page to combined_text\n",
    "        combined_text += f\"\\n\\nPage {page_number + 1}:\\n{text}\"\n",
    "\n",
    "        # Get the images from the page\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        # Extract and process each image\n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = pdf_document.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image_ext = base_image[\"ext\"]\n",
    "            image_filename = f\"page_{page_number+1}_img_{img_index+1}.{image_ext}\"\n",
    "            image_filepath = os.path.join(output_folder, image_filename)\n",
    "\n",
    "            # Save the image to the output folder\n",
    "            with open(image_filepath, \"wb\") as image_file:\n",
    "                image_file.write(image_bytes)\n",
    "\n",
    "            # Encode the image to base64\n",
    "            base64_image = encode_image(image_filepath)\n",
    "\n",
    "            # Use GPT-4o to describe the image and extract text\n",
    "            image_description = describe_image(base64_image)\n",
    "\n",
    "            # Add the image description and reference to combined_text\n",
    "            combined_text += f\"\\n\\n[Image: {image_filename}]\\n{image_description}\"\n",
    "\n",
    "            print(f\"Processed {image_filename} on page {page_number + 1}\")\n",
    "\n",
    "    print(\"Processing complete.\")\n",
    "\n",
    "    # Return the combined text\n",
    "    return combined_text\n",
    "\n",
    "# # Example usage\n",
    "# pdf_path = \"PA - Consolidated lecture notes.pdf\"\n",
    "# output_folder = \"extracted_images_new\"\n",
    "# combined_text = extract_images_and_text_from_pdf(pdf_path, output_folder)\n",
    "\n",
    "# # Optionally save the combined text to a file\n",
    "# with open(\"combined_text.txt\", \"w\") as text_file:\n",
    "#     text_file.write(combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Page 1:\n",
      "Product Sense -\n",
      "How to tackle product strategy and business acumen rounds in\n",
      "interviews?\n",
      "Lecture Objective:\n",
      "How to address business acumen questions round :\n",
      "●\n",
      "Analyzing a metric change. What’s a metric?\n",
      "●\n",
      "Defining metrics to measure performance / success of a new feature / product.\n",
      "Importance of product strategy & business acumen rounds -\n",
      "●\n",
      "Apart from building models, developing dashboards and reporting frameworks -\n",
      "One of the main responsibilities of a data scientist is to extract insights from\n",
      "data and work with product managers and engineering teams to deliver\n",
      "actionable plans to improve the product.\n",
      "●\n",
      "Product sense is about understanding all possibilities, not finding one correct\n",
      "answer.\n",
      "Example Questions: Product Acumen / Business Acumen\n",
      "●\n",
      "Why did Youtube’s traffic drop by 5%?\n",
      "●\n",
      "How would you measure the success of the “Save Post” feature on Facebook?\n",
      "●\n",
      "What metrics would you define to measure the health of the product search in\n",
      "Amazon?\n",
      "●\n",
      "We have a dashboard tracking our metrics and the avg ETA is up by 3 min. How\n",
      "would you investigate this problem?\n",
      "\n",
      "\n",
      "Page 2:\n",
      "______________________________________________________________________________\n",
      "Flow of Discussion between CEO, Product Manager and Data Scientist.\n",
      "CEO: Good morning, team. I'd like to discuss the upcoming launch of our new feature.\n",
      "Product Manager, could you provide an overview of what we're planning?\n",
      "Product Manager: Certainly, CEO. We're introducing a new in-app messaging feature\n",
      "that allows users to chat with customer support directly. This should greatly enhance\n",
      "the user experience and improve our customer service.\n",
      "Data Scientist: That's great news. To ensure its success, I suggest we monitor user\n",
      "engagement and response times closely. We should track metrics like chat usage,\n",
      "response rates, and customer satisfaction.\n",
      "CEO: Agreed. Data Scientist, can you set up a framework to collect and analyze\n",
      "these metrics? Also, are there any early insights you can share about user behavior in\n",
      "our app that might be relevant to this feature?\n",
      "Data Scientist: I'll get the data collection in place. As for user behavior, we've seen\n",
      "that users tend to spend a lot of time on our help center articles, which indicates a\n",
      "need for better support options. This new feature aligns well with that behavior.\n",
      "Product Manager: It's reassuring to hear that. We're planning to roll out the feature to\n",
      "a small segment of users first to gather feedback. Data Scientist, do you have any\n",
      "recommendations for how we can structure A/B testing to measure its impact\n",
      "effectively?\n",
      "Data Scientist: Certainly. We should set up the A/B test to compare user behavior\n",
      "and satisfaction between those with access to the new feature and those without.\n",
      "This will help us gauge its impact on engagement and customer satisfaction.\n",
      "\n",
      "\n",
      "Page 3:\n",
      "CEO: Sounds like a solid plan. Let's move forward with this strategy, and once we have\n",
      "collected enough data, we can reconvene to evaluate the feature's performance. Thank\n",
      "you, team.\n",
      "Product Manager: Thank you, CEO. We're excited about this launch and the positive\n",
      "impact it can have on our users.\n",
      "Data Scientist: Agreed. Let's work together to make sure we're making data-driven\n",
      "decisions every step of the way.\n",
      "______________________________________________________________________________\n",
      "Key responsibilities taken by the CEO, Product Manager, and Data\n",
      "Scientist in the above discussion:\n",
      "CEO:\n",
      "●\n",
      "Setting the overall direction and vision for the company.\n",
      "●\n",
      "Initiating the discussion and requesting an overview of the new feature.\n",
      "●\n",
      "Agreeing to monitor user engagement and response times.\n",
      "●\n",
      "Leading the decision-making process and giving final approval.\n",
      "Product Manager:\n",
      "●\n",
      "Providing an overview of the new in-app messaging feature.\n",
      "●\n",
      "Highlighting the potential benefits of the feature for the user experience and\n",
      "customer service.\n",
      "●\n",
      "Suggesting the rollout of the feature to a small user segment for feedback.\n",
      "●\n",
      "Seeking recommendations on structuring A/B testing to measure the feature's\n",
      "impact effectively.\n",
      "Data Scientist:\n",
      "●\n",
      "Suggesting the need to monitor user engagement and response times.\n",
      "●\n",
      "Recommending the collection and analysis of specific metrics related to the\n",
      "feature, such as chat usage, response rates, and customer satisfaction.\n",
      "\n",
      "\n",
      "Page 4:\n",
      "●\n",
      "Offering insights into user behavior in the app, such as users spending time on\n",
      "help center articles.\n",
      "●\n",
      "Proposing the setup of A/B testing to compare user behavior and satisfaction\n",
      "between users with and without access to the new feature.\n",
      "●\n",
      "Agreeing to work on making data-driven decisions and collecting relevant data.\n",
      "These responsibilities reflect the different roles and expertise of the CEO, Product\n",
      "Manager, and Data Scientist in the context of launching a new feature and ensuring its\n",
      "success.\n",
      "______________________________________________________________________________\n",
      "Judgment Criteria & General Framework -\n",
      "Keep this in mind when addressing business acumen questions.\n",
      "●\n",
      "Judgment Criteria for Interviewers :\n",
      "○\n",
      "Structure - Demonstrate a systematic approach\n",
      "○\n",
      "Comprehensiveness - Covers all important aspects\n",
      "○\n",
      "Feasibility - Practical enough that it could be implemented realistically\n",
      "●\n",
      "General Framework to keep in mind :\n",
      "○\n",
      "Clarify\n",
      "○\n",
      "Plan\n",
      "○\n",
      "Conclude\n",
      "\n",
      "\n",
      "[Image: page_4_img_1.png]\n",
      "**Extracted Text:**\n",
      "\n",
      "```\n",
      "                           GENERAL FRAMEWORK\n",
      "                           \n",
      "01\n",
      "Clarify\n",
      "Dont give a solution without understanding the problem. Ask questions to understand the business context and define the key objective\n",
      "\n",
      "02\n",
      "Plan\n",
      "Its okay to take a minute to gather your thoughts on the solution. Plan the metrics / hypothesis\n",
      "\n",
      "03\n",
      "Conclude\n",
      "Summarize the key points ( from objective, to solution & recommendation (if any))\n",
      "```\n",
      "\n",
      "**Summary:**\n",
      "\n",
      "The General Framework consists of three key steps:\n",
      "\n",
      "1. **Clarify**: Understand the problem fully before proposing a solution. Ask questions to grasp the business context and establish the main objective.\n",
      "2. **Plan**: Take a moment to collect your thoughts regarding the solution and outline the necessary metrics or hypotheses.\n",
      "3. **Conclude**: Summarize the main points from the objective through to the solution and any recommendations.\n",
      "\n",
      "Page 5:\n",
      "Different Product Sense Problems -\n",
      "1. Product Diagnostics - Analyzing a metric change.\n",
      "Case - You notice that the percentage of users who clicked on a search result about a\n",
      "Facebook Event increased 15% week-over-week. How would you investigate this?\n",
      "General Framework -\n",
      "\n",
      "\n",
      "[Image: page_5_img_1.png]\n",
      "### Extracted Text\n",
      "\n",
      "**Different kinds of Product Sense Problems**\n",
      "\n",
      "01  \n",
      "**Product Diagnostics -**  \n",
      "Analyse a metric change  \n",
      "- Investigate why our new user sign up increased by 15% yesterday  \n",
      "- ETA of cab service has increased by 10%  \n",
      "- ‘Add To Cart’ Conversion has decreased by 5%  \n",
      "\n",
      "02  \n",
      "**New Product / Feature -**  \n",
      "Measuring performance / success  \n",
      "- How would you measure the health of the product search in Amazon?  \n",
      "- What metrics would you use to define the success of the save feature on FB?  \n",
      "\n",
      "03  \n",
      "**Product Design -**  \n",
      "Launch feature recommendation  \n",
      "- Should we change the address bar of our mobile browser to the bottom?  \n",
      "- Add more marketing promotion emails for our newly signed-up users?  \n",
      "- Make it mandatory to upload pictures in the sign up process itself?  \n",
      "\n",
      "04  \n",
      "**Product Improvement**  \n",
      "- How would you improve content creation on TikTok?  \n",
      "- How would you improve Maps?  \n",
      "\n",
      "### Summary\n",
      "\n",
      "The image presents different types of product sense problems divided into four categories:\n",
      "\n",
      "1. **Product Diagnostics**: Focuses on analyzing metric changes such as new user sign-ups, ETA of cab services, and 'Add To Cart' conversion rates.\n",
      "  \n",
      "2. **New Product / Feature**: Involves measuring performance and success, particularly in product search health on platforms like Amazon and defining success metrics for features on Facebook.\n",
      "\n",
      "3. **Product Design**: Discusses recommendations for launching\n",
      "\n",
      "Page 6:\n",
      "1. Clarify: Ask clarifying questions and share what your thoughts about it are.\n",
      "Below is an example of how you could drive this with the interviewer.\n",
      "○\n",
      "What does a search result success for an event mean?\n",
      "■\n",
      "Does it refer to when a user searches for something in the search\n",
      "bar on Facebook and the results produce a Facebook event?\n",
      "■\n",
      "These search results could belong to different categories, like a\n",
      "Facebook Event, Page, or Group - and the success is defined when\n",
      "you click on the event\n",
      "\n",
      "\n",
      "[Image: page_6_img_1.png]\n",
      "**Extracted Text:**\n",
      "\n",
      "Product Diagnostics - General Framework  \n",
      "You notice that the percent of users that clicked on a search result about a FB Event increased 15% week-over-week. How would you investigate this?  \n",
      "   \n",
      "C - Clarify  \n",
      "R - Rule Out  \n",
      "I - Internal  \n",
      "E - External  \n",
      "D - Data  \n",
      "  \n",
      "CRIED  \n",
      "  \n",
      "Justin Beiber  \n",
      "8.6K people are talking about this  \n",
      "Justin Bieber  \n",
      "Public group · 405K members  \n",
      "This is fan group. for all beliebers...❤❤  \n",
      "80 posts a day  \n",
      "\n",
      "Justin Bieber  \n",
      "Page · 88,656,642 followers  \n",
      "16 mins · Recently seen · Photo dump...  \n",
      "luv u guyzzz  \n",
      "29.3K 1.6K Comments 567 Shares  \n",
      "\n",
      "Business Insider  \n",
      "Page · 9.7M likes · Business & Economy Web...  \n",
      "18 hrs · Blatt Billiards has been building custom pool tables for nearly 100 years.  \n",
      "BUSINESSINSIDER.COM  \n",
      "How $100,000 custom pool tables are made for celebrities like Justin Bieber...\n",
      "\n",
      "---\n",
      "\n",
      "**Summary:**\n",
      "\n",
      "The image presents a \"Product Diagnostics - General Framework\" discussing an incident where the percentage of users clicking on a Facebook Event increased by 15% week-over-week. The suggested investigation framework is outlined as \"CRIED,\" which stands for:  \n",
      "- C - Clarify  \n",
      "- R - Rule Out  \n",
      "- I - Internal  \n",
      "- E - External  \n",
      "- D - Data  \n",
      "\n",
      "Additionally, it includes\n",
      "\n",
      "[Image: page_6_img_2.png]\n",
      "**Extracted Text:**\n",
      "\n",
      "```\n",
      "            CRIED\n",
      "               |\n",
      "     ---------------------\n",
      "    |                     |\n",
      " Clarify             Rule out\n",
      "                           |\n",
      "                   --------------------\n",
      "                  |                    |\n",
      "        Internal & External       Data\n",
      "```\n",
      "\n",
      "**Summary:**\n",
      "The image depicts a diagram titled \"CRIED,\" which has two main branches stemming from it: \"Clarify\" and \"Rule Out.\" Under \"Rule Out,\" there is a further division into \"Internal & External\" and \"Data.\" The structure represents a thought process or methodology.\n",
      "\n",
      "Page 7:\n",
      "○\n",
      "You could also clarify the definition of the metric in question.\n",
      "■\n",
      "15% increase = # users who clicked on event result after searching\n",
      "/ # of users who searched for any keyword.\n",
      "■\n",
      "15% WoW = 15% increase in success rate compared to last week?\n",
      "Or there has been a 15% increase over the past few weeks.\n",
      "2. Rule Out: Rule out any change in metric happening due to technical issues or\n",
      "infrastructural glitch / bugs or outliers.\n",
      "○\n",
      "Has there been any bug in the logging code because of which event clicks\n",
      "have been de-duped?\n",
      "○\n",
      "Is it a 3rd-party software tracking the search result clicks? If so, is there\n",
      "any glitch in that software?\n",
      "○\n",
      "Any data pipeline failure?\n",
      "○\n",
      "Ask about outliers - Did the metrics for the week get affected by one\n",
      "day’s data alone or has it been a consistent increase?\n",
      "3. Internal Data: Explore the internal factors that could have affected the metric.\n",
      "Acronym: TROPiCS\n",
      "○\n",
      "T - Time:\n",
      "■\n",
      "Is this 15% increase seasonal / sudden / gradual?\n",
      "■\n",
      "Sudden Increase - could mean there is a bug in the logging of a\n",
      "new feature or update that's recently launched (ranking change?).\n",
      "This is creating problems so you may need to roll back.\n",
      "■\n",
      "Gradual Increase - may indicate a change in user behavior. Maybe\n",
      "users are starting to prefer live virtual events over physical events\n",
      "due to covid restrictions\n",
      "○\n",
      "R - Region:\n",
      "■\n",
      "Is this change concentrated in a specific region or is it evenly\n",
      "distributed globally?\n",
      "■\n",
      "For example, we are slowly coming out of the pandemic and some\n",
      "\n",
      "\n",
      "Page 8:\n",
      "cities have started to reopen. In which case, the rising interest in\n",
      "events may only be concentrated in those cities that are not\n",
      "re-opened\n",
      "○\n",
      "O - Other related features affected:\n",
      "■\n",
      "If an interest in events is going up, do we see a similar jump in\n",
      "Instagram or Facebook stories because users attending these\n",
      "events will have more content to post about?\n",
      "○\n",
      "P - Platform:\n",
      "■\n",
      "Are we seeing this increase across both Android / iOS?\n",
      "■\n",
      "Across Mobile / Desktop?\n",
      "■\n",
      "Across Mac / Windows?\n",
      "■\n",
      "If only one of them is seeing an increase, we should explore if\n",
      "there’s an engineering bug with the platform that has caused a\n",
      "glitch\n",
      "○\n",
      "C - Cannibalization: If the metric for a product is decreasing, is it because\n",
      "another product we offer is cannibalizing engagement?\n",
      "Alternatively, if the metric in question is increasing, are we cannibalizing\n",
      "from our other offerings?\n",
      "■\n",
      "Around the time when the spike in event clicks happened, are we\n",
      "seeing a decrease in # clicks on profiles/pages / groups?\n",
      "■\n",
      "Is there a specific category that we’re cannibalizing from or is it\n",
      "evenly distributed?\n",
      "■\n",
      "For instance, is it only users that previously clicked on Groups (not\n",
      "Pages) that are clicking on Events now?\n",
      "●\n",
      "This may indicate that we made a change to the ranking of\n",
      "Groups in our search results.\n",
      "●\n",
      "Did we down rank it? Or accidentally remove it completely?\n",
      "○\n",
      "S - Segmentation: Slice and dice the data to identify the demographic of\n",
      "\n",
      "\n",
      "Page 9:\n",
      "users this increase has affected.\n",
      "■\n",
      "Age - Are we noticing this increase only amongst teenagers /\n",
      "young adults / middle age or senior users?\n",
      "■\n",
      "Gender - Is this increase only among female users? Or across both\n",
      "genders\n",
      "■\n",
      "Power Vs Casual Users - Are we observing this increase only\n",
      "among those users that are less active on FB?\n",
      "■\n",
      "New Vs Existing Users - Are we observing this increase only\n",
      "among those users that recently joined FB? Are the existing users\n",
      "still exhibiting same behaviors\n",
      "4. External Data:\n",
      "○\n",
      "Industry/Competitor\n",
      "■\n",
      "Did the # of users attending events on Twitter decrease?\n",
      "■\n",
      "A new competitor has joined the market.\n",
      "■\n",
      "Are competitors changing their offering?\n",
      "○\n",
      "Good PR\n",
      "○\n",
      "It could also be due to seasonality or a major temporary event.\n",
      "■\n",
      "If it’s a major temporary event, you should see KPIs begin to return\n",
      "to their normal state shortly.\n",
      "2. Measure Product Performance / Success - Defining metrics\n",
      "Case - PM reaches out to you after launch of a new save feature on Facebook to assess\n",
      "the success of this feature. Define the metrics you would like to measure.\n",
      "\n",
      "\n",
      "Page 10:\n",
      "1. Clarify: Ask clarifying questions about the new feature / product and the main\n",
      "objective behind its release (monetization, engagement, retention etc).\n",
      "○\n",
      "Is this save feature used to allow users to Save Links, Pages, Posts,\n",
      "Locations, Movies, etc. to view later?\n",
      "○\n",
      "Does this also remind users about what items they have saved later?\n",
      "○\n",
      "Are we focusing on both aspects of this feature or only the first?\n",
      "●\n",
      "Who Benefits from This Feature: This feature affects users and marketer?\n",
      "○\n",
      "Marketers do not want to be forgotten, so if they post something that\n",
      "attracts the attention of the user, they want the user to be able to find it\n",
      "again later if they don't have immediate time to spend on it.\n",
      "○\n",
      "For example, if there is a nice shoe advertised on FB and the user likes it,\n",
      "but cannot check it now, or there is a discussion about a TV series that\n",
      "the user potentially finds interesting to watch later, the user can save it to\n",
      "check it out later.\n",
      "●\n",
      "Business Goals:\n",
      "○\n",
      "User Goal: The benefit for users is that they do not need to copy paste or\n",
      "take a screenshot of the post they want to check out later. They can have\n",
      "\n",
      "\n",
      "[Image: page_10_img_1.png]\n",
      "**Extracted Text:**\n",
      "\n",
      "```\n",
      "New Feature - Define Metrics\n",
      "PM reaches out to you after launch of a new save feature on FB to assess success of this feature\n",
      "\n",
      "01\n",
      "Clarify\n",
      "\n",
      "02\n",
      "Explain Business Goal with Feature\n",
      "\n",
      "03\n",
      "Define Metrics\n",
      "\n",
      "04\n",
      "Summarise\n",
      "```\n",
      "\n",
      "**Summary:**\n",
      "The image outlines a process for defining metrics for a new Facebook save feature following its launch. It includes four steps: Clarify, Explain Business Goal with Feature, Define Metrics, and Summarise.\n",
      "\n",
      "Page 11:\n",
      "all these items in a categorized way (e.g., Movies, Pages) and can check\n",
      "them later.\n",
      "○\n",
      "Marketer Goal: Increases revenue for marketers by increasing clicks and\n",
      "impressions.\n",
      "○\n",
      "BIZ Goal: Increases user engagement.\n",
      "■Increase revenue by increasing CTR, and CPC and CPM. Because\n",
      "the user might make a click that he would not have done\n",
      "otherwise if they could not save the post. So, the goal is to\n",
      "increase CTR and consequently the revenue.\n",
      "●\n",
      "Define Metrics:\n",
      "Please note that not all elements are applicable to all problem statements.\n",
      "1. Awareness:\n",
      "a. Discoverability:\n",
      "i.\n",
      "% of users the have at least once Saved an item\n",
      "1. This shows that the users know about this feature.\n",
      "ii.\n",
      "# of returns to saved content per user\n",
      "\n",
      "\n",
      "[Image: page_11_img_1.png]\n",
      "**Extracted Text:**\n",
      "\n",
      "New Feature - Define Metrics\n",
      "\n",
      "AAAEERR\n",
      "\n",
      "01  \n",
      "Awareness  \n",
      "How many people are aware your brand exists? number of website visits, time spent on a website, email open rate etc  \n",
      "\n",
      "01  \n",
      "Engagement  \n",
      "What is the breadth and frequency of user engagement? DAU, MAU time spent in a session, session frequency, actions taken in the product, likes, comments etc  \n",
      "\n",
      "02  \n",
      "Acquisition  \n",
      "How many people are interacting with your product? number of leads, number of qualified leads, sign ups, downloads, install, chatbot interactions  \n",
      "\n",
      "02  \n",
      "Revenue  \n",
      "How many people are paying for your product? CTR, % of paid customers; average revenue per customer; conversion rate of trial to paid customers;  \n",
      "\n",
      "03  \n",
      "Activation  \n",
      "How many people are realizing the value of your product? number of connections made, number of times an action is performed, number of steps completed  \n",
      "\n",
      "03  \n",
      "Retention / Renewal  \n",
      "How often are your users coming back? % of users coming back to your platform each day, month, year; churn rates; customer lifetime value  \n",
      "\n",
      "---\n",
      "\n",
      "**Summary:**\n",
      "\n",
      "The image introduces a new feature that defines essential metrics for tracking user engagement and business performance. It includes categories such as Awareness (measuring brand awareness), Engagement (breadth and frequency of user interaction), Acquisition (interactions with the product), Revenue (payment metrics), Activation (realization of product value), and Retention/Renewal (user retention over time\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loaders = TextLoader(\"combined_text.txt\")\n",
    "\n",
    "print(loaders.load()[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 60,\n",
    "    separators=[\"\\n\\n\",\"\\n\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = text_splitter.split_documents(loaders.load())\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    api_key=api_key,\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=api_endpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FAISS\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m db = \u001b[43mFAISS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(db.index.ntotal)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MS/Project/Lexivis/.venv/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:844\u001b[39m, in \u001b[36mVectorStore.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, **kwargs)\u001b[39m\n\u001b[32m    841\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[32m    842\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m] = ids\n\u001b[32m--> \u001b[39m\u001b[32m844\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MS/Project/Lexivis/.venv/lib/python3.12/site-packages/langchain_community/vectorstores/faiss.py:1043\u001b[39m, in \u001b[36mFAISS.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m   1016\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_texts\u001b[39m(\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1023\u001b[39m     **kwargs: Any,\n\u001b[32m   1024\u001b[39m ) -> FAISS:\n\u001b[32m   1025\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[32m   1026\u001b[39m \n\u001b[32m   1027\u001b[39m \u001b[33;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1041\u001b[39m \u001b[33;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m     embeddings = \u001b[43membedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1044\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__from(\n\u001b[32m   1045\u001b[39m         texts,\n\u001b[32m   1046\u001b[39m         embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1050\u001b[39m         **kwargs,\n\u001b[32m   1051\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MS/Project/Lexivis/.venv/lib/python3.12/site-packages/langchain_openai/embeddings/base.py:588\u001b[39m, in \u001b[36mOpenAIEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts, chunk_size)\u001b[39m\n\u001b[32m    585\u001b[39m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[32m    586\u001b[39m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[32m    587\u001b[39m engine = cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m.deployment)\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MS/Project/Lexivis/.venv/lib/python3.12/site-packages/langchain_openai/embeddings/base.py:483\u001b[39m, in \u001b[36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[39m\u001b[34m(self, texts, engine, chunk_size)\u001b[39m\n\u001b[32m    481\u001b[39m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] = []\n\u001b[32m    482\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[32m--> \u001b[39m\u001b[32m483\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invocation_params\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    487\u001b[39m         response = response.model_dump()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MS/Project/Lexivis/.venv/lib/python3.12/site-packages/openai/resources/embeddings.py:128\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    122\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    123\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    124\u001b[39m             ).tolist()\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MS/Project/Lexivis/.venv/lib/python3.12/site-packages/openai/_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MS/Project/Lexivis/.venv/lib/python3.12/site-packages/openai/_base_client.py:919\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    917\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MS/Project/Lexivis/.venv/lib/python3.12/site-packages/openai/_base_client.py:1023\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1020\u001b[39m         err.response.read()\n\u001b[32m   1022\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1026\u001b[39m     cast_to=cast_to,\n\u001b[32m   1027\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1031\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1032\u001b[39m )\n",
      "\u001b[31mNotFoundError\u001b[39m: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "db = FAISS.from_documents(splits, embeddings)\n",
    "print(db.index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
